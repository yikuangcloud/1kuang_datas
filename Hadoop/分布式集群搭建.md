# 完全分布式集群搭建  
## 一、准备3台客户机（关闭防火墙、静态ip、主机名称）
### 克隆虚拟机（因为毕设，我的是弄了五台）
#### 1、关闭需要被克隆的虚拟机    
&ensp; 该虚拟机中已关闭防火墙、opt目录下创建好了module和software文件夹、创建新用户drift并设置root权限，如果未设置则先进行相应操作  
**opt目录下创建文件夹：**  
1）在/opt目录下创建module、software文件夹，第一次先删除rh  
非root用户下，比如drift用户下，使用sudo rm -rf rh/  
&ensp; [drift@hadoop101 opt]$ sudo mkdir module   
&ensp; [drift@hadoop101 opt]$ sudo mkdir software   
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/%E5%9B%BE1.png"/>  
<p align="center">
</p>
</p>  
2）修改module、software文件夹的所有者   
  
[drift@hadoop101 opt]$ sudo chown drift:drift module/ software/     
[atguigu@hadoop101 opt]$ ll   
总用量 8   
drwxr-xr-x. 2 drift drift 4096 1月  17 14:37 module   
drwxr-xr-x. 2 drift drift 4096 1月  17 14:38 software  
  
**永久关闭防火墙：**  
1）查看防火墙开机启动状态  
&ensp; [root@hadoop100桌面]#chkconfig iptables --list  
2）设置开机时关闭防火墙  
&ensp; [root@hadoop100桌面]#chkconfig iptables off  

**创建新用户drift并设置root权限：**  
创建新用户  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/%E5%9B%BE2.png"/>  
<p align="center">
</p>
</p>  
修改权限（设置drift用户具有root权限）：vim /etc/sudoers  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/%E5%9B%BE3.png"/>  
<p align="center">
</p>
</p>  
修改完毕，现在可以用drift帐号登录，然后用命令 su -，即可获得root权限进行操作。    

#### 2、找到克隆选项    
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/%E5%9B%BE4.png"/>  
<p align="center">
</p>
</p>  

#### 3、欢迎界面
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/5.png"/>  
<p align="center">
</p>
</p>  

#### 4、克隆虚拟机
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/6.png"/>  
<p align="center">
</p>
</p>  

#### 5、选择“创建完整的虚拟机”
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/7.png"/>  
<p align="center">
</p>
</p>  

#### 6、自定义“虚拟机名称”和“位置”
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/8.png"/>  
<p align="center">
</p>
</p>  

#### 7、等待克隆完成
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/9.png"/>  
<p align="center">
</p>
</p>  

#### 8、完成克隆，点击关闭即可
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/10.png"/>  
<p align="center">
</p>
</p>  

### 修改静态IP地址  
#### 9、修改克隆后的虚拟机ip  
修改命令：vim /etc/udev/rules.d/70-persistent-net.rules  
进入如下页面，删除eth0该行；将eth1修改为eth0，同时复制物理ip地址，修改网卡如下图  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/11.png"/>  
<p align="center">
</p>
</p>  

<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/12.png"/>  
<p align="center">
</p>
</p>  

#### 10、修改IP地址  
修改命令：vim /etc/sysconfig/network-scripts/ifcfg-eth0  
1）把上一步骤所复制的物理ip地址更改  
&ensp; HWADDR=00:0C:2x:6x:0x:xx  
2）修改成自己的ip  
&ensp; IPADDR=192.168.164.101  

### 修改主机名
#### 11、修改主机名
修改命令：vim /etc/sysconfig/network  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/13.png"/>  
<p align="center">
</p>
</p>  

### 关闭防火墙
#### 12、关闭防火墙
关闭命令：chkconfig iptables off  
查看状态命令：service iptables status  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/14.png"/>  
<p align="center">
</p>
</p>  

#### 13、重启服务器即可
重启命令：reboot  

**注意：集群多台虚拟机重复上述操作**   

### 本地和虚拟机互ping测试
本地ping虚拟机  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/15.png"/>  
<p align="center">
</p>
</p>  

虚拟机互ping  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/16.png"/>  
<p align="center">
</p>
</p>  

## 二、安装JDK&配置环境变量
注意：  
&ensp; 第一次安装时通过sudo rm -rf *删除opt目录下的所有文件（其实是空的）  

#### 1、卸载现有JDK
1）查询是否安装Java软
&ensp; [drift@hadoop101 opt]$ rpm -qa | grep java  
2）如果安装的版本低于1.7，卸载该JD
&ensp; [drift@hadoop101 opt]$ sudo rpm -e 软件包  
3）查看JDK安装路径：  
&ensp; [drift@hadoop101 ~]$ which java  

#### 2、用SecureCRT工具将JDK导入到opt目录下面的software文件夹下面，如下图所示
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/17.png"/>  
<p align="center">
</p>
</p>  

#### 3、“alt+p”进入sftp模式，如下图所示
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/18.png"/>  
<p align="center">
</p>
</p>  

#### 4、选择jdk1.8拖入，如下图所示  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/19.png"/>  
<p align="center">
</p>
</p>  

#### 5、拖入成功显示  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/20.png"/>  
<p align="center">
</p>
</p>  

#### 6、在Linux系统下的opt目录中查看软件包是否导入成功
[drift@hadoop101 opt]$ cd software/  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/21.png"/>  
<p align="center">
</p>
</p>  

#### 7、解压JDK到/opt/module目录下
[drift@hadoop101 software]$ tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/22.png"/>  
<p align="center">
</p>
</p>  

#### 8、配置JDK环境变量
1）先获取JDK路径  
&ensp; [drift@hadoop101 jdk1.8.0_144]$ pwd  
&ensp; &ensp; /opt/module/jdk1.8.0_144  
2）打开/etc/profile文件  
&ensp; [drift@hadoop101 software]$ sudo vim /etc/profile  
&ensp; 在profile文件末尾添加JDK路径  
```
#JAVA_HOME  
export JAVA_HOME=/opt/module/jdk1.8.0_144  
export PATH=$PATH:$JAVA_HOME/bin  
```    
3）保存后退出   
&ensp; :wq  
4）让修改后的文件生效  
&ensp; [drift@hadoop101 jdk1.8.0_144]$ source /etc/profile  

#### 9、测试JDK是否安装成功
[drift@hadoop101 jdk1.8.0_144]# java -version  
&ensp; java version "1.8.0_144"  
&ensp; &ensp; 注意：重启（如果java -version可以用就不用重启）  
[drift@hadoop101 jdk1.8.0_144]$ sync  
[drift@hadoop101 jdk1.8.0_144]$ sudo reboot  

**注意：**  
&ensp; 后续虚拟机通过scp命令复制JDK到每台机器中  
&ensp; 复制文件：scp -r /opt/module/jdk1.8.0_144/ drift@hadoop102:/opt/module/  
&ensp; 复制环境变量：sudo scp /etc/profile root@hadoop102:/etc/profile         
&ensp; 使环境变量生效（每台机器都需要）：source /etc/profile   

**编写集群分发脚本xsync**  
1、在/home/drift目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下：  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/23.png"/>  
<p align="center">
</p>
</p>  

2、在bin目录下创建xsync文件，并添加以下内容
```
#!/bin/bash
#1 获取输入参数个数，如果没有参数，直接退出
pcount=$#
if((pcount==0)); then
echo no args;
exit;
fi

#2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname

#3 获取上级目录到绝对路径 –P指向实际物理地址，防止软连接
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir

#4 获取当前用户名称
user=`whoami`

#5 循环
for((host=102; host<106; host++)); do
        echo ------------------- hadoop$host --------------
        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
done
```  

3、修改脚本xsync具有执行权限  
[drift@hadoop101 bin]$ chmod 777 xsync  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/24.png"/>  
<p align="center">
</p>
</p>  

4、调用脚本形式：xsync文件名称    
[drift@hadoop101 bin]$ xsync /home/drift/bin/   
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/25.png"/>  
<p align="center">
</p>
</p>  

**注意：**  
&ensp; 如果将xsync放到/home/atguigu/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。  

## 三、安装Hadoop&配置环境变量
集群部署：  
**注意：**  
&ensp; 如果是三台虚拟机，就只需要搭建hadoop101-hadoop103即可  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/26.jpg"/>  
<p align="center">
</p>
</p>  

#### 1、以JDK同样方式复制Hadoop安装包到机器上  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/27.png"/>  
<p align="center">
</p>
</p>  

#### 2、解压Hadoop到/opt/module
&ensp; [drift@hadoop101 software]$ tar -zxvf hadoop-2.7.2.tar.gz -C /opt/module/  
后续通过xsync脚本将hadoop分发到集群各个机器上  
&ensp; [drift@hadoop101 module]$ xsync /opt/module/hadoop-2.7.2/  

## 四、配置集群
#### 1、核心配置文件
配置core-site.xml  
```
<!-- 指定HDFS中NameNode的地址 -->
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://hadoop101:9000</value>
</property>
<!-- 指定Hadoop运行时产生文件的存储目录 -->
<property>
    <name>hadoop.tmp.dir</name>
    <value>/opt/module/hadoop-2.7.2/data/tmp</value>
</property>
```  

#### 2、HDFS配置文件
配置hadoop-env.sh（替换）  
```
export JAVA_HOME=/opt/module/jdk1.8.0_144
```  

配置hdfs-site.xml  
```
<property>
    <name>dfs.replication</name>
    <value>3</value>
</property>
<!-- 指定Hadoop辅助名称节点主机配置 -->
<property>
    <name>dfs.namenode.secondary.http-address</name>
    <value>hadoop103:50090</value>
</property>
```  

#### 3、配置YARN
配置yarn-env.sh（解除注释修改）  
```
export JAVA_HOME=/opt/module/jdk1.8.0_144
```  

配置yarn-site.xml  
```
<!-- Reducer获取数据的方式 -->
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>
<!-- 指定YARN的ResourceManager的地址 -->
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>hadoop102</value>
</property>
<!-- 日志聚集功能使能 -->
<property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
</property>
<!-- 日志保留时间设置7天 -->
<property>
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>604800</value>
</property>
```  

#### 4、MapReduce配置文件
配置mapred-env.sh   
```
export JAVA_HOME=/opt/module/jdk1.8.0_144
```  

配置mapred-site.xml  
```
[drift@hadoop102 hadoop]$ mv mapred-site.xml.template mapred-site.xml
[drift@hadoop102 hadoop]$ vim mapred-site.xml

<!-- 指定MR运行在Yarn上 -->
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
```  

#### 5、Hadoop配置文件分发
```
[drift@hadoop101 hadoop]$ xsync /opt/module/hadoop-2.7.2/etc/hadoop/
```  

## 五、单点启动
#### 1、如果集群是第一次启动，需要格式化NameNode  
```
[drift@hadoop101 hadoop-2.7.2]$ bin/hdfs namenode -format
```  

#### 2、在hadoop101上启动NameNode
```
[drift@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode
```

#### 3、在hadoop102-105上分别启动DataNode
```
sbin/hadoop-daemon.sh start datanode
```

#### 4、jps查看
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/28.jpg"/>  
<p align="center">
</p>
</p>  

#### 5、测试
查看HDFS命令：bin/hadoop fs + 相应操作命令 或者 bin/hdfs dfs + 相应操作命令  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/29.jpg"/>  
<p align="center">
</p>
</p>  

网址： http://hadoop101:50070/   
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/30.png"/>  
<p align="center">
</p>
</p>  

## 六、配置ssh
#### 1、SSH无密码登录（hadoop101和hadoop102都要生成）
```
[drift@hadoop101 hadoop-2.7.2]$ ssh hadoop102
  atguigu@hadoop103's password:
  Last login: Fri Aug 16 14:34:13 2019 from hadoop101
[drift@hadoop102 ~]$ hostname
  hadoop102
```  

#### 2、无密钥配置
**hadoop101配置：**  
（1）进入到我的home目录：cd  ~/.ssh   
（2）生成公钥和私钥：  
```
[drift@hadoop101 .ssh]$ ssh-keygen -t rsa 
  然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥） 
[drift@hadoop101 .ssh]$ ll
  总用量 12
  -rw-------. 1 drift drift 1675 8月  16 15:30 id_rsa
  -rw-r--r--. 1 drift drift 399 8月  16 15:30 id_rsa.pub
  -rw-r--r--. 1 drift drift 814 8月  16 14:06 known_hosts
```  
（3）将公钥拷贝到要免密登录的目标机器上 ssh-copy-id hadoop102、ssh-copy-id hadoop103、ssh-copy-id hadoop104、ssh-copy-id hadoop105  
```
[drift@hadoop101 .ssh]$ ssh-copy-id hadoop101  输入密码
[drift@hadoop101 .ssh]$ ssh-copy-id hadoop102  输入密码
[drift@hadoop101 .ssh]$ ssh-copy-id hadoop103  输入密码
[drift@hadoop101 .ssh]$ ssh-copy-id hadoop104  输入密码
[drift@hadoop101 .ssh]$ ssh-copy-id hadoop105  输入密码
```  
（4）在hadoop101下  
```
[drift@hadoop101 .ssh]$ ssh hadoop102
  known_hosts
```  
  
**hadoop102配置：**  
**因为ResourceManager是配置在这台机器的，如果是配置在hadoop101上则只需要在101生成**  
（1）进入到我的home目录cd  ~/.ssh   
（2）生成公钥和私钥：  
```
[drift@hadoop102 .ssh]$ ssh-keygen -t rsa
  然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）
[drift@hadoop102 .ssh]$ ll
  总用量 16
  -rw-------. 1 drift drift 399 8月  16 15:31 authorized_keys
  -rw-------. 1 drift drift 1675 8月  17 11:12 id_rsa
  -rw-r--r--. 1 drift drift  399 8月  17 11:12 id_rsa.pub
  -rw-r--r--. 1 drift drift 1221 8月  17 10:22 known_hosts
```  
（3）将公钥拷贝到要免密登录的目标机器上ssh-copy-id hadoop102、ssh-copy-id hadoop103、ssh-copy-id hadoop104、ssh-copy-id hadoop105  
```
[drift@hadoop101 .ssh]$ ssh-copy-id hadoop101  输入密码
[drift@hadoop101 .ssh]$ ssh-copy-id hadoop102  输入密码
[drift@hadoop101 .ssh]$ ssh-copy-id hadoop103  输入密码
[drift@hadoop101 .ssh]$ ssh-copy-id hadoop104  输入密码
[drift@hadoop101 .ssh]$ ssh-copy-id hadoop105  输入密码
```   
（4）在hadoop102下  
```
[drift@hadoop102 .ssh]$ ssh hadoop101
```  

**注意：**  
&ensp; 因为ResourceManager节点在hadoop102上，所以采用drift账号配置一下无密登录到hadoop101、hadoop102、hadoop103、hadoop104、hadoop105服务器上。  
&ensp; 如果在hadoop101上需要采用root账号访问其它服务器，配置一下无密登录到hadoop101、hadoop102、hadoop103、hadoop104、hadoop105。  
  
.ssh文件夹下的文件功能解释  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/32.png"/>  
<p align="center">
</p>
</p>  

## 七、群起并测试集群
#### 1、配置slaves  
```
/opt/module/hadoop-2.7.2/etc/hadoop/slaves
[drift@hadoop102 hadoop]$ vim slaves
```
在该文件中增加如下内容：  
```
hadoop101
hadoop102
hadoop103
hadoop104
hadoop105
```
注意：  
&ensp; 该文件中添加的内容结尾不允许有空格，文件中不允许有空行。  
  
同步所有节点配置文件  
```
[drift@hadoop102 hadoop]$ xsync slaves
```
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/33.png"/>  
<p align="center">
</p>
</p>  

#### 2、启动集群
**注意：**  
如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）  
```
[drift@hadoop102 hadoop-2.7.2]$ bin/hdfs namenode -format
```
启动HDFS  
```
[drift@hadoop101 hadoop-2.7.2]$ sbin/start-dfs.sh
[drift@hadoop101 hadoop-2.7.2]$ jps
```
启动YARN（注意安装节点位置）  
```
[drift@hadoop102 hadoop-2.7.2]$ sbin/start-yarn.sh
```  
**注意：**  
&ensp; NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/34.jpg"/>  
<p align="center">
</p>
</p>  

#### 3、web端查看SecondaryNameNode
网址： http://hadoop103:50090/status.html

#### 4、集群测试（上传大小文件）
随便准备一个文档上传测试就行  
```
[drift@hadoop101 hadoop-2.7.2]$ bin/hadoop fs -put wcinput/wc.input /user/drift/input
[drift@hadoop101 hadoop-2.7.2]$ bin/hadoop fs -put /opt/software/hadoop-2.7.2.tar.gz /user/drift/input
```
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/36.png"/>  
<p align="center">
</p>
</p>  

<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/37.jpg"/>  
<p align="center">
</p>
</p>  

上传后查看文件位置：  
```
[drift@hadoop101 hadoop-2.7.2]$ cd data/tmp/dfs/data/current/BP-886705812-192.168.164.101-1584939216275/current/finalized/subdir0/subdir0/
```
注意：两个文件都有存储在hadoop101上，而hadoop102上只有一个文件存储  
<p align="center">
<img src="https://github.com/Dr11ft/BigDataGuide/blob/master/Pics/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/38.jpg"/>  
<p align="center">
</p>
</p>  

查看上传文件内容：  
查看小文件：  
```
[drift@hadoop101 subdir0]$ cat blk_1073741825
```
查看大文件：  
先拼接在一个文件，因为文件是压缩包，所以再解压  
```
[drift@hadoop102 subdir0]$ cat blk_1073741836>>tmp.file
[drift@hadoop102 subdir0]$ cat blk_1073741837>>tmp.file
[drift@hadoop102 subdir0]$ tar -zxvf tmp.file
```

## 八、集群启动/停止方式总结
#### 1、各个服务组件逐一启动/停止
（1）分别启动/停止HDFS组件  
```
hadoop-daemon.sh  start / stop  namenode / datanode / secondarynamenode
```
（2）启动/停止YARN  
```
yarn-daemon.sh  start / stop  resourcemanager / nodemanager
```
**注意：**  
&ensp; 单节点启动这种方式的使用场景，一般集群已经启动完毕了，单独添加或者删除节点的时候使用  
#### 2、各个模块分开启动/停止（配置ssh是前提）&emsp; 常用
（1）整体启动/停止HDFS  
```
start-dfs.sh   /  stop-dfs.sh
```
（2）整体启动/停止YARN  
```
start-yarn.sh  /  stop-yarn.sh
```


